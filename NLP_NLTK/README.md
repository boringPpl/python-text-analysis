## Natural Language Processing with NLTK

This workshop addresses various topics in Natural Language Processing, primarily through the use of NLTK.
We'll work with a corpus of documents and learn how to identify different types of linguistic structure in
the text, which can help in classifying the documents or extracting useful information from them. We'll
cover tokenization, part of speech (POS) tagging, chunking of phrases, named entity recognition (NER), and
dependency parsing.

__Prior knowledge:__ Attendees should have thorough knowledge of Python. Completion of D-Lab's Python for Everything series will be sufficient.

__Technology requirements:__ Please install Python 3 and the following packages before the workshop.
* NLTK (In Bash: $ pip install nltk)
* Brown corpus from NLTK (In Python: >>> nltk.download('brown'))
* Movie Reviews corpus from NLTK (In Python: >>> nltk.download('movie_reviews'))
* [Stanford Parser](http://nlp.stanford.edu/software/lex-parser.html#Download): Download the Stanford Parser 3.6.0 and unzip to a location that's easy for you to find (e.g. a folder called SourceCode in your Documents folder)

